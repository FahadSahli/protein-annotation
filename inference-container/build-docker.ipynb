{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Build an image that can do training and inference in SageMaker\r\n",
      "# This is a Python 2 image that uses the nginx, gunicorn, flask stack\r\n",
      "# for serving inferences in a stable way.\r\n",
      "\r\n",
      "FROM ubuntu:20.04\r\n",
      "\r\n",
      "MAINTAINER Amazon AI <sage-learner@amazon.com>\r\n",
      "\r\n",
      "ARG PYTHON_VERSION_TAG=3.8.3\r\n",
      "ARG LINK_PYTHON_TO_PYTHON3=1\r\n",
      "\r\n",
      "RUN apt-get -y update && apt-get install -y --no-install-recommends \\\r\n",
      "         wget \\\r\n",
      "         nginx \\\r\n",
      "         ca-certificates \\\r\n",
      "    && rm -rf /var/lib/apt/lists/*\r\n",
      "    \r\n",
      "RUN apt-get -qq -y update && \\\r\n",
      "    DEBIAN_FRONTEND=noninteractive apt-get -qq -y install \\\r\n",
      "        gcc \\\r\n",
      "        g++ \\\r\n",
      "        zlibc \\\r\n",
      "        zlib1g-dev \\\r\n",
      "        libssl-dev \\\r\n",
      "        libbz2-dev \\\r\n",
      "        libsqlite3-dev \\\r\n",
      "        libncurses5-dev \\\r\n",
      "        libgdbm-dev \\\r\n",
      "        libgdbm-compat-dev \\\r\n",
      "        liblzma-dev \\\r\n",
      "        libreadline-dev \\\r\n",
      "        uuid-dev \\\r\n",
      "        libffi-dev \\\r\n",
      "        tk-dev \\\r\n",
      "        curl \\\r\n",
      "        git \\\r\n",
      "        make \\\r\n",
      "        sudo \\\r\n",
      "        bash-completion \\\r\n",
      "        tree \\\r\n",
      "        vim \\\r\n",
      "        software-properties-common && \\\r\n",
      "    mv /usr/bin/lsb_release /usr/bin/lsb_release.bak && \\\r\n",
      "    apt-get -y autoclean && \\\r\n",
      "    apt-get -y autoremove && \\\r\n",
      "    rm -rf /var/lib/apt/lists/*\r\n",
      "\r\n",
      "#RUN wget https://bootstrap.pypa.io/get-pip.py && python get-pip.py\r\n",
      "#RUN apt-get -y update && apt-get install -y --no-install-recommends python3.5 \r\n",
      "\r\n",
      "# Here we get all python packages.\r\n",
      "# There's substantial overlap between scipy and numpy that we eliminate by\r\n",
      "# linking them together. Likewise, pip leaves the install caches populated which uses\r\n",
      "# a significant amount of space. These optimizations save a fair amount of space in the\r\n",
      "# image, which reduces start up time.\r\n",
      "#tensorflow==2.3.0\r\n",
      "#RUN wget https://bootstrap.pypa.io/3.3/get-pip.py && python3.5 get-pip.py\r\n",
      "COPY install_python.sh install_python.sh\r\n",
      "RUN bash install_python.sh ${PYTHON_VERSION_TAG} ${LINK_PYTHON_TO_PYTHON3} && \\\r\n",
      "    rm -r install_python.sh Python-${PYTHON_VERSION_TAG}\r\n",
      "\r\n",
      "#RUN apt-get install -y python3-pip\r\n",
      "#tensorflow-cpu\r\n",
      "RUN pip3 install --upgrade pip\r\n",
      "RUN pip3 install numpy==1.16.0 scipy scikit-learn tensorflow pandas==1.0.1 flask gevent gunicorn boto3\r\n",
      "\r\n",
      "#RUN apt-get install python-is-python3\r\n",
      "#RUN ln -s /usr/bin/python3 /usr/bin/python && \\\r\n",
      "#    ln -s /usr/bin/pip3 /usr/bin/pip\r\n",
      "    \r\n",
      "# Set some environment variables. PYTHONUNBUFFERED keeps Python from buffering our standard\r\n",
      "# output stream, which means that logs can be delivered to the user quickly. PYTHONDONTWRITEBYTECODE\r\n",
      "# keeps Python from writing the .pyc files which are unnecessary in this case. We also update\r\n",
      "# PATH so that the train and serve programs are found when the container is invoked.\r\n",
      "# Use C.UTF-8 locale to avoid issues with ASCII encoding\r\n",
      "\r\n",
      "ENV LC_ALL=C.UTF-8\r\n",
      "ENV LANG=C.UTF-8\r\n",
      "\r\n",
      "ENV PYTHONUNBUFFERED=TRUE\r\n",
      "ENV PYTHONDONTWRITEBYTECODE=TRUE\r\n",
      "ENV PATH=\"/opt/program:${PATH}\"\r\n",
      "\r\n",
      "# Set up the program in the image\r\n",
      "COPY ProtCNN /opt/program\r\n",
      "WORKDIR /opt/program"
     ]
    }
   ],
   "source": [
    "!cat container/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/protein-annotation/inference-container/container\n",
      "Sending build context to Docker daemon  377.9kB\n",
      "Step 1/17 : FROM ubuntu:20.04\n",
      " ---> f643c72bc252\n",
      "Step 2/17 : MAINTAINER Amazon AI <sage-learner@amazon.com>\n",
      " ---> Using cache\n",
      " ---> 326b3d86eee1\n",
      "Step 3/17 : ARG PYTHON_VERSION_TAG=3.8.3\n",
      " ---> Using cache\n",
      " ---> 439310e2c915\n",
      "Step 4/17 : ARG LINK_PYTHON_TO_PYTHON3=1\n",
      " ---> Using cache\n",
      " ---> dbb5d06e3d11\n",
      "Step 5/17 : RUN apt-get -y update && apt-get install -y --no-install-recommends          wget          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 5f43ad46e6dd\n",
      "Step 6/17 : RUN apt-get -qq -y update &&     DEBIAN_FRONTEND=noninteractive apt-get -qq -y install         gcc         g++         zlibc         zlib1g-dev         libssl-dev         libbz2-dev         libsqlite3-dev         libncurses5-dev         libgdbm-dev         libgdbm-compat-dev         liblzma-dev         libreadline-dev         uuid-dev         libffi-dev         tk-dev         curl         git         make         sudo         bash-completion         tree         vim         software-properties-common &&     mv /usr/bin/lsb_release /usr/bin/lsb_release.bak &&     apt-get -y autoclean &&     apt-get -y autoremove &&     rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 7e3f10a511aa\n",
      "Step 7/17 : COPY install_python.sh install_python.sh\n",
      " ---> Using cache\n",
      " ---> df527da06b05\n",
      "Step 8/17 : RUN bash install_python.sh ${PYTHON_VERSION_TAG} ${LINK_PYTHON_TO_PYTHON3} &&     rm -r install_python.sh Python-${PYTHON_VERSION_TAG}\n",
      " ---> Using cache\n",
      " ---> c9ba70d0c5a7\n",
      "Step 9/17 : RUN pip3 install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 4fb41eb647ae\n",
      "Step 10/17 : RUN pip3 install numpy==1.16.0 scipy scikit-learn tensorflow pandas==1.0.1 flask gevent gunicorn boto3\n",
      " ---> Using cache\n",
      " ---> b7f0786a371f\n",
      "Step 11/17 : ENV LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> d81982c03df4\n",
      "Step 12/17 : ENV LANG=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> f1103152693f\n",
      "Step 13/17 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> c28d6097a86c\n",
      "Step 14/17 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> 465aabdd9c01\n",
      "Step 15/17 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 22113d090241\n",
      "Step 16/17 : COPY ProtCNN /opt/program\n",
      " ---> Using cache\n",
      " ---> 16dfa3c481c4\n",
      "Step 17/17 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> c991120bd95e\n",
      "Successfully built c991120bd95e\n",
      "Successfully tagged port-cnn-15:latest\n",
      "/home/ec2-user/SageMaker/protein-annotation/inference-container\n"
     ]
    }
   ],
   "source": [
    "%cd container\n",
    "!docker build -t port-cnn-15 .\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "{\n",
      "    \"repository\": {\n",
      "        \"repositoryArn\": \"arn:aws:ecr:us-east-1:877465308896:repository/port-cnn-15\",\n",
      "        \"registryId\": \"877465308896\",\n",
      "        \"repositoryName\": \"port-cnn-15\",\n",
      "        \"repositoryUri\": \"877465308896.dkr.ecr.us-east-1.amazonaws.com/port-cnn-15\",\n",
      "        \"createdAt\": 1607546024.0,\n",
      "        \"imageTagMutability\": \"MUTABLE\",\n",
      "        \"imageScanningConfiguration\": {\n",
      "            \"scanOnPush\": false\n",
      "        },\n",
      "        \"encryptionConfiguration\": {\n",
      "            \"encryptionType\": \"AES256\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "The push refers to repository [877465308896.dkr.ecr.us-east-1.amazonaws.com/port-cnn-15]\n",
      "\n",
      "\u001b[1Bc53ef381: Preparing \n",
      "\u001b[1Bc0f5558d: Preparing \n",
      "\u001b[1Bec89fa3b: Preparing \n",
      "\u001b[1Ba32e9379: Preparing \n",
      "\u001b[1B4d331419: Preparing \n",
      "\u001b[1B62557a9d: Preparing \n",
      "\u001b[1Bb99c5c09: Preparing \n",
      "\u001b[1B3634dc78: Preparing \n",
      "\u001b[1Bf84dbbe9: Preparing \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[9Bc0f5558d: Pushed   1.637GB/1.619GB\u001b[6A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[3A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[2A\u001b[2K\u001b[4A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[9A\u001b[2K\u001b[4A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[1A\u001b[2K\u001b[9A\u001b[2K\u001b[4A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[1A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[1A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[1A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[1A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2Klatest: digest: sha256:d745f88d1423ce219bbbb66ce2cffde755450db25ed5453fe2f50ce1f258a3a7 size: 2421\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "ecr_repository = 'port-cnn-15'\n",
    "tag = ':latest'\n",
    "uri_suffix = 'amazonaws.com'\n",
    "port_cnn_uri = '{}.dkr.ecr.{}.{}/{}'.format(account_id, region, uri_suffix, ecr_repository + tag)\n",
    "\n",
    "# Create ECR repository and push docker image\n",
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)\n",
    "!aws ecr create-repository --repository-name $ecr_repository\n",
    "!docker tag {ecr_repository + tag} $port_cnn_uri\n",
    "!docker push $port_cnn_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "prefix = 'ProtCNN-Endpoint'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "#image = '{}.dkr.ecr.{}.amazonaws.com/port-cnn:latest'.format(account, region)\n",
    "model_name = \"PortCNN-prediction-10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = '{}.dkr.ecr.{}.amazonaws.com/port-cnn-15:latest'.format(account, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'877465308896.dkr.ecr.us-east-1.amazonaws.com/port-cnn-15:latest'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage = boto3.Session().client(service_name='sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_container = {\n",
    "    'Image': image,\n",
    "    'ModelDataUrl': \"s3://sagemaker-us-east-1-877465308896/tensorflow-training-201202-1559-002-4534ac0c/output/model.tar.gz\",\n",
    "}\n",
    "\n",
    "create_model_response = sage.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name_prefix = 'PortCNN-inference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint configuration name: PortCNN-inference-epc--2020-12-09-21-22-50\n",
      "Endpoint configuration arn:  arn:aws:sagemaker:us-east-1:877465308896:endpoint-config/portcnn-inference-epc--2020-12-09-21-22-50\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_config_name = job_name_prefix + '-epc-' + timestamp\n",
    "endpoint_config_response = sage.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.m5.4xlarge', #'ml.m5.4xlarge'\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print('Endpoint configuration name: {}'.format(endpoint_config_name))\n",
    "print('Endpoint configuration arn:  {}'.format(endpoint_config_response['EndpointConfigArn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker = boto3.client(service_name='sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: PortCNN-inference-ep--2020-12-09-21-22-55\n",
      "EndpointArn = arn:aws:sagemaker:us-east-1:877465308896:endpoint/portcnn-inference-ep--2020-12-09-21-22-55\n",
      "CPU times: user 7.76 ms, sys: 4.05 ms, total: 11.8 ms\n",
      "Wall time: 218 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_name = job_name_prefix + '-ep-' + timestamp\n",
    "print('Endpoint name: {}'.format(endpoint_name))\n",
    "\n",
    "endpoint_params = {\n",
    "    'EndpointName': endpoint_name,\n",
    "    'EndpointConfigName': endpoint_config_name,\n",
    "}\n",
    "endpoint_response = sagemaker.create_endpoint(**endpoint_params)\n",
    "print('EndpointArn = {}'.format(endpoint_response['EndpointArn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EndpointStatus = Creating\n",
      "Endpoint creation ended with EndpointStatus = InService\n"
     ]
    }
   ],
   "source": [
    "# get the status of the endpoint\n",
    "response = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = response['EndpointStatus']\n",
    "print('EndpointStatus = {}'.format(status))\n",
    "\n",
    "\n",
    "# wait until the status has changed\n",
    "sagemaker.get_waiter('endpoint_in_service').wait(EndpointName=endpoint_name)\n",
    "\n",
    "\n",
    "# print the status of the endpoint\n",
    "endpoint_response = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = endpoint_response['EndpointStatus']\n",
    "print('Endpoint creation ended with EndpointStatus = {}'.format(status))\n",
    "\n",
    "if status != 'InService':\n",
    "    raise Exception('Endpoint creation failed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = s3.Object(\"sagemaker-us-east-1-877465308896\",\"test-2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "payloads = obj.get()['Body'].read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFLFSGRREVMADACLQGMMGCVYGTAGGMDSAAAVLGDFCFLAGKPEERLIAWDYGRQYLLLAPPDAAWRELIKKVLGDRAREHTRYAIKKEGDCFDPGRLRTLAETLPAGITLSRIHGELYGKCLKEEWSRDLVSCFPSCEAYEAMGLGVAALRGNELLAGASSYARSRDAIEIEIDTREDMRNRGLASACGAALILECLERGLYPSWDAHTEISAALAEKLGYHVSHPYVVY\n",
      "MVDVGGKPVSRRTAAASATVLLGEKAFWLVKENQLAKGDALAVAQIAGIMAAKQTSALIPLCHPIPLDRVAVSLELVEPGWRVVVTATCVASGRTGVEMEALTAASLAALALYDMCKAVTRDIVIQDVRLLSKTGG\n",
      "VLDVACGTCDVAMEARNQTGDAAFIIGTDFSPGMLTLGLQKLKKNRRFATIPLVCANALALPFQSTHFDAVLIAFGIRNIMDRKGALKQFHDALKPGG\n",
      "VVLERASLESVKVGKEYQLLNCDRHKGIAKKFKRDISTCRPDITHQCLLMLMDSPLNRAGLLQVFIRTEKNILIEINPQTRIPRTFDRFCGLMVQLLQKFSIHALDGNVKLLKVIKNPITDHFPNGCMKIGTSFSAEVVQDPTSVMTSTTNNDDDDAPIVFVVGAISRGSIDVDYVEKTISLSSYPLSAALTCAKLCGAFE\n",
      "MVDVGGKPVSRRTAAASATVLLGEKAFWLVKENQLAKGDALAVAQIAGIMAAKQTSALIPLCHPIPLDRVAVSLELVEPGWRVVVTATCVASGRTGVEMEALTAASLAALALYDMCKAVTRDIVIQDVRLLSKTGG\n"
     ]
    }
   ],
   "source": [
    "for element in payloads.split(\"\\r\\n\")[:-1]:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "payloads = payloads.split(\"\\r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "runtime = boto3.Session().client(service_name='runtime.sagemaker') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'ac0e7f8d-d99c-45a6-b8ba-371894aa6f0d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'ac0e7f8d-d99c-45a6-b8ba-371894aa6f0d', 'x-amzn-invoked-production-variant': 'AllTraffic', 'date': 'Wed, 9 Dec 2020 21:37:04 GMT', 'content-type': 'text/csv; charset=utf-8', 'content-length': '46'}, 'RetryAttempts': 0}, 'ContentType': 'text/csv; charset=utf-8', 'InvokedProductionVariant': 'AllTraffic', 'Body': <botocore.response.StreamingBody object at 0x7fb5b36b53c8>}\n"
     ]
    }
   ],
   "source": [
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                           ContentType= 'text/csv', \n",
    "                                           Body=payloads[0] + \"\\r\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = response['Body'].read().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"(\\'PF12746.7\\', \\'GNAT_acetyltran\\', 0.9372136)\"\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PF12746.7', 'GNAT_acetyltran', '0.9372136']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Match ' OR \" OR ( OR ) OR \\n\n",
    "re.sub(\"\\'|\\\"|\\(|\\)|\\n\", '', r).split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(re.sub(\"\\'|\\\"|\\(|\\)|\\n\", '', r).split(\", \")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "for payload in payloads:\n",
    "    if (payload != ''):\n",
    "        response = runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                           ContentType= 'text/csv', \n",
    "                                           Body=payload + \"\\r\\n\")\n",
    "        response = json.loads(response['Body'].read().decode())\n",
    "        response = re.sub(\"\\'|\\\"|\\(|\\)|\\n\", '', response).split(\", \")\n",
    "        response.append(payload)\n",
    "        \n",
    "        responses.append(tuple(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PF12746.7',\n",
       "  'GNAT_acetyltran',\n",
       "  '0.9372136',\n",
       "  'AFLFSGRREVMADACLQGMMGCVYGTAGGMDSAAAVLGDFCFLAGKPEERLIAWDYGRQYLLLAPPDAAWRELIKKVLGDRAREHTRYAIKKEGDCFDPGRLRTLAETLPAGITLSRIHGELYGKCLKEEWSRDLVSCFPSCEAYEAMGLGVAALRGNELLAGASSYARSRDAIEIEIDTREDMRNRGLASACGAALILECLERGLYPSWDAHTEISAALAEKLGYHVSHPYVVY'),\n",
       " ('PF01967.21',\n",
       "  'MoaC',\n",
       "  '0.99998176',\n",
       "  'MVDVGGKPVSRRTAAASATVLLGEKAFWLVKENQLAKGDALAVAQIAGIMAAKQTSALIPLCHPIPLDRVAVSLELVEPGWRVVVTATCVASGRTGVEMEALTAASLAALALYDMCKAVTRDIVIQDVRLLSKTGG'),\n",
       " ('PF13649.6',\n",
       "  'Methyltransf_25',\n",
       "  '0.99475324',\n",
       "  'VLDVACGTCDVAMEARNQTGDAAFIIGTDFSPGMLTLGLQKLKKNRRFATIPLVCANALALPFQSTHFDAVLIAFGIRNIMDRKGALKQFHDALKPGG'),\n",
       " ('PF03587.14',\n",
       "  'EMG1',\n",
       "  '0.99998105',\n",
       "  'VVLERASLESVKVGKEYQLLNCDRHKGIAKKFKRDISTCRPDITHQCLLMLMDSPLNRAGLLQVFIRTEKNILIEINPQTRIPRTFDRFCGLMVQLLQKFSIHALDGNVKLLKVIKNPITDHFPNGCMKIGTSFSAEVVQDPTSVMTSTTNNDDDDAPIVFVVGAISRGSIDVDYVEKTISLSSYPLSAALTCAKLCGAFE'),\n",
       " ('PF01967.21',\n",
       "  'MoaC',\n",
       "  '0.99998176',\n",
       "  'MVDVGGKPVSRRTAAASATVLLGEKAFWLVKENQLAKGDALAVAQIAGIMAAKQTSALIPLCHPIPLDRVAVSLELVEPGWRVVVTATCVASGRTGVEMEALTAASLAALALYDMCKAVTRDIVIQDVRLLSKTGG')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PF12746.7\n",
      "GNAT_acetyltran\n",
      "0.9372136\n",
      "AFLFSGRREVMADACLQGMMGCVYGTAGGMDSAAAVLGDFCFLAGKPEERLIAWDYGRQYLLLAPPDAAWRELIKKVLGDRAREHTRYAIKKEGDCFDPGRLRTLAETLPAGITLSRIHGELYGKCLKEEWSRDLVSCFPSCEAYEAMGLGVAALRGNELLAGASSYARSRDAIEIEIDTREDMRNRGLASACGAALILECLERGLYPSWDAHTEISAALAEKLGYHVSHPYVVY\n",
      "sssssssssssssssssssssss\n",
      "PF01967.21\n",
      "MoaC\n",
      "0.99998176\n",
      "MVDVGGKPVSRRTAAASATVLLGEKAFWLVKENQLAKGDALAVAQIAGIMAAKQTSALIPLCHPIPLDRVAVSLELVEPGWRVVVTATCVASGRTGVEMEALTAASLAALALYDMCKAVTRDIVIQDVRLLSKTGG\n",
      "sssssssssssssssssssssss\n",
      "PF13649.6\n",
      "Methyltransf_25\n",
      "0.99475324\n",
      "VLDVACGTCDVAMEARNQTGDAAFIIGTDFSPGMLTLGLQKLKKNRRFATIPLVCANALALPFQSTHFDAVLIAFGIRNIMDRKGALKQFHDALKPGG\n",
      "sssssssssssssssssssssss\n",
      "PF03587.14\n",
      "EMG1\n",
      "0.99998105\n",
      "VVLERASLESVKVGKEYQLLNCDRHKGIAKKFKRDISTCRPDITHQCLLMLMDSPLNRAGLLQVFIRTEKNILIEINPQTRIPRTFDRFCGLMVQLLQKFSIHALDGNVKLLKVIKNPITDHFPNGCMKIGTSFSAEVVQDPTSVMTSTTNNDDDDAPIVFVVGAISRGSIDVDYVEKTISLSSYPLSAALTCAKLCGAFE\n",
      "sssssssssssssssssssssss\n",
      "PF01967.21\n",
      "MoaC\n",
      "0.99998176\n",
      "MVDVGGKPVSRRTAAASATVLLGEKAFWLVKENQLAKGDALAVAQIAGIMAAKQTSALIPLCHPIPLDRVAVSLELVEPGWRVVVTATCVASGRTGVEMEALTAASLAALALYDMCKAVTRDIVIQDVRLLSKTGG\n",
      "sssssssssssssssssssssss\n"
     ]
    }
   ],
   "source": [
    "for a, b, c, d in responses:\n",
    "    print(a)\n",
    "    print(b)\n",
    "    print(c)\n",
    "    print(d)\n",
    "    print(\"sssssssssssssssssssssss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client(\"s3\")\n",
    "import codecs\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = client.get_object(Bucket=\"sagemaker-us-east-1-877465308896\", Key=\"dict_class.csv\")\n",
    "protein_classes = {}\n",
    "    \n",
    "for protein_classes in csv.DictReader(codecs.getreader(\"utf-8\")(data[\"Body\"])):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_path = 's3://{}/{}/'.format(\"sagemaker-us-east-1-877465308896\", 'batch-data')\n",
    "output_data_path = 's3://{}/{}/'.format(\"sagemaker-us-east-1-877465308896\", 'batch-results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s3://sagemaker-us-east-1-877465308896/batch-data/',\n",
       " 's3://sagemaker-us-east-1-877465308896/batch-results/')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_path, output_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................\n",
      "\u001b[34mStarting the inference server with 16 workers.\u001b[0m\n",
      "\u001b[34m2020/12/09 21:46:17 [crit] 10#10: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:17 +0000] \"GET /ping HTTP/1.1\" 502 166 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/12/09 21:46:18 [crit] 10#10: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:18 +0000] \"GET /ping HTTP/1.1\" 502 166 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [9] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [9] [INFO] Listening at: unix:/tmp/gunicorn.sock (9)\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [9] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [12] [INFO] Booting worker with pid: 12\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [13] [INFO] Booting worker with pid: 13\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [14] [INFO] Booting worker with pid: 14\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [15] [INFO] Booting worker with pid: 15\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.346924: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.346957: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [18] [INFO] Booting worker with pid: 18\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [19] [INFO] Booting worker with pid: 19\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.396020: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.396054: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.438833: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.438867: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.532784: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.532817: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.616396: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.616430: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.641070: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.641101: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.706765: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.706812: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.726803: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.726852: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.873580: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.873633: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.915190: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.915463: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.987821: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.987870: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.033829: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.034121: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.052391: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.052438: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.067489: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.067536: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.109513: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.109556: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.186865: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.186913: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.265262: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.265575: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.265784: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.266213: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.321027: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.322038: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c18b2c30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.322294: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.432978: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.433019: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.433051: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.433316: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.464546: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.465320: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cc50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.465351: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.574063: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.574177: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.574427: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.574896: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.603631: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.604606: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cad0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.604674: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.736808: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.736849: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.744086: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.744369: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.761210: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.762002: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cad0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.762032: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.309278: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.309323: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.309356: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.309638: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.413254: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.414055: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c8e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.414095: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.424006: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.424047: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.424079: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.424346: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.497206: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.497991: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.498028: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.530170: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.530219: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.530255: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.530579: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.607732: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.607778: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.607810: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.608061: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.625196: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.626012: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cad0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.626046: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.685224: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.685988: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c670 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.686021: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.009792: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.009839: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.009874: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.017203: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.109227: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.110057: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c610 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.110093: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.294954: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.322467: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.322755: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.323326: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.343352: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.343394: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.343425: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.343672: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.413214: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.413961: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cd80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.413993: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.517237: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.518271: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c610 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.518310: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.559732: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.559785: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.559823: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.560134: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.646973: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.654109: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cb90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.654152: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.669952: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.669998: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.670030: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.670291: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.753207: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.754008: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cd80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.754051: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.780932: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.780988: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.781022: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.781333: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.853228: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.854007: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c9c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.854046: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:23.057599: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:23.057952: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:23.058139: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:23.058589: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:23.093293: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:23.094317: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cb60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:23.094600: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:24.523984: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:24.524031: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:24.524066: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:24.524357: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:24.649061: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:24.650249: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c370 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:24.650485: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:27 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:27 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:27 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 36 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 47 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 44 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 46 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 46 \"-\" \"Go-http-client/1.1\"\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2020-12-09T21:46:27.411:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=1, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 37 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 37 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 44 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 38 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 38 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 39 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 37 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 37 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 44 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 38 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 38 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 39 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 39 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 38 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:30 +0000] \"POST /invocations HTTP/1.1\" 200 37 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:30 +0000] \"POST /invocations HTTP/1.1\" 200 47 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:30 +0000] \"POST /invocations HTTP/1.1\" 200 48 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:30 +0000] \"POST /invocations HTTP/1.1\" 200 36 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 39 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 38 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:30 +0000] \"POST /invocations HTTP/1.1\" 200 37 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:30 +0000] \"POST /invocations HTTP/1.1\" 200 47 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:30 +0000] \"POST /invocations HTTP/1.1\" 200 48 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:30 +0000] \"POST /invocations HTTP/1.1\" 200 36 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mStarting the inference server with 16 workers.\u001b[0m\n",
      "\u001b[34m2020/12/09 21:46:17 [crit] 10#10: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:17 +0000] \"GET /ping HTTP/1.1\" 502 166 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mStarting the inference server with 16 workers.\u001b[0m\n",
      "\u001b[35m2020/12/09 21:46:17 [crit] 10#10: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:17 +0000] \"GET /ping HTTP/1.1\" 502 166 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/12/09 21:46:18 [crit] 10#10: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:18 +0000] \"GET /ping HTTP/1.1\" 502 166 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [9] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [9] [INFO] Listening at: unix:/tmp/gunicorn.sock (9)\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [9] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [12] [INFO] Booting worker with pid: 12\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [13] [INFO] Booting worker with pid: 13\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [14] [INFO] Booting worker with pid: 14\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [15] [INFO] Booting worker with pid: 15\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.346924: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.346957: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [18] [INFO] Booting worker with pid: 18\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [19] [INFO] Booting worker with pid: 19\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.396020: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.396054: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.438833: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.438867: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.532784: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.532817: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[35m2020/12/09 21:46:18 [crit] 10#10: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:18 +0000] \"GET /ping HTTP/1.1\" 502 166 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [9] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [9] [INFO] Listening at: unix:/tmp/gunicorn.sock (9)\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [9] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [12] [INFO] Booting worker with pid: 12\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [13] [INFO] Booting worker with pid: 13\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [14] [INFO] Booting worker with pid: 14\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [15] [INFO] Booting worker with pid: 15\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.346924: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.346957: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [18] [INFO] Booting worker with pid: 18\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [19] [INFO] Booting worker with pid: 19\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.396020: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.396054: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.438833: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.438867: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.532784: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.532817: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.616396: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.616430: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.641070: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.641101: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.706765: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.706812: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.726803: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.726852: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m[2020-12-09 21:46:18 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.873580: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2020-12-09 21:46:18.873633: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.915190: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.915463: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.987821: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:18.987870: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.033829: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.034121: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.052391: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.052438: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.067489: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.616396: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.616430: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.641070: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.641101: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.706765: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.706812: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.726803: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.726852: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m[2020-12-09 21:46:18 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.873580: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.873633: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.915190: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.915463: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.987821: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:18.987870: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:19.033829: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:19.034121: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:19.052391: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:19.052438: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:19.067489: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.067536: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.109513: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.109556: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.186865: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:19.186913: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:19.067536: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:19.109513: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:19.109556: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:19.186865: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:19.186913: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.265262: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.265575: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.265784: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.266213: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[35mBuilding model...\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.265262: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.265575: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.265784: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.266213: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.321027: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.322038: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c18b2c30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.322294: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.432978: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.433019: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.433051: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.433316: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.464546: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.465320: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cc50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.465351: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.574063: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.574177: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.574427: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.574896: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.603631: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.604606: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cad0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.604674: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.321027: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.322038: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c18b2c30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.322294: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[35mBuilding model...\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.432978: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.433019: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.433051: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.433316: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.464546: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.465320: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cc50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.465351: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[35mBuilding model...\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.574063: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.574177: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.574427: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.574896: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.603631: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.604606: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cad0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.604674: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.736808: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.736849: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.744086: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.744369: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.761210: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.762002: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cad0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:20.762032: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.309278: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.309323: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.309356: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.309638: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[35mBuilding model...\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.736808: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.736849: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.744086: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.744369: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.761210: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.762002: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cad0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:20.762032: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[35mBuilding model...\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.309278: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.309323: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.309356: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.309638: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.413254: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.414055: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c8e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.414095: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.424006: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.424047: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.424079: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.424346: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.497206: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.497991: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.498028: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.530170: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.530219: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.530255: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.530579: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.607732: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.607778: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.607810: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.608061: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[35mBuilding model...\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.413254: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.414055: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c8e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.414095: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.424006: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.424047: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.424079: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.424346: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[35mBuilding model...\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.497206: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.497991: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.498028: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.530170: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.530219: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.530255: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.530579: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[35mBuilding model...\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.607732: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.607778: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.607810: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.608061: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.625196: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.626012: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cad0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.626046: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.625196: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.626012: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cad0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.626046: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.685224: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.685988: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c670 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:21.686021: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.009792: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.009839: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.009874: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.017203: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.109227: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.110057: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c610 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.110093: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.685224: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.685988: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c670 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:21.686021: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[35mBuilding model...\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.009792: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.009839: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.009874: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.017203: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.109227: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.110057: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c610 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.110093: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.294954: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.322467: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.322755: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.323326: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.343352: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.343394: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.343425: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.343672: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.413214: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.413961: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cd80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.413993: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[35mDone building model...\u001b[0m\n",
      "\u001b[35mRestoring model...\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[35mBuilding model...\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.294954: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.322467: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.322755: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.323326: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35mBuilding model...\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.343352: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.343394: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.343425: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.343672: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.413214: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.413961: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cd80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.413993: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.517237: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.518271: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c610 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.518310: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.559732: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.559785: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.559823: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.560134: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.517237: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.518271: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c610 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.518310: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[35mBuilding model...\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.559732: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.559785: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.559823: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.560134: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[35mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.646973: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.654109: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cb90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.654152: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.669952: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.669998: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.670030: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.646973: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.654109: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cb90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.654152: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.669952: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.669998: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.670030: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.670291: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.753207: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.754008: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cd80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.754051: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.780932: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.780988: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.781022: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.781333: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.853228: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.854007: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c9c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:22.854046: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:23.057599: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:23.057952: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:23.058139: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:23.058589: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:23.093293: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:23.094317: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cb60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:23.094600: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.670291: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[35mBuilding model...\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.753207: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.754008: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cd80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.754051: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.780932: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.780988: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.781022: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.781333: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.853228: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.854007: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c9c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:22.854046: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[35mBuilding model...\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:23.057599: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:23.057952: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:23.058139: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:23.058589: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:23.093293: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:23.094317: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4cb60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:23.094600: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[35mDone building model...\u001b[0m\n",
      "\u001b[35mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[34mBuilding model...\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:24.523984: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:24.524031: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:24.524066: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:24.524357: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[35mDone building model...\u001b[0m\n",
      "\u001b[35mRestoring model...\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:From /opt/program/predictor.py:12: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.config.run_functions_eagerly` instead of the experimental version.\u001b[0m\n",
      "\u001b[35mBuilding model...\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:24.523984: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:24.524031: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:24.524066: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a4c9c9401387): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:24.524357: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[35mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:24.649061: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:24.650249: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c370 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-12-09 21:46:24.650485: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:24.649061: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:24.650249: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5598c1e4c370 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[35m2020-12-09 21:46:24.650485: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[35mDone building model...\u001b[0m\n",
      "\u001b[35mRestoring model...\u001b[0m\n",
      "\u001b[35mDone building model...\u001b[0m\n",
      "\u001b[35mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[35mDone building model...\u001b[0m\n",
      "\u001b[35mRestoring model...\u001b[0m\n",
      "\u001b[35mDone building model...\u001b[0m\n",
      "\u001b[35mRestoring model...\u001b[0m\n",
      "\u001b[35mDone building model...\u001b[0m\n",
      "\u001b[35mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone building model...\u001b[0m\n",
      "\u001b[34mRestoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[35mDone building model...\u001b[0m\n",
      "\u001b[35mRestoring model...\u001b[0m\n",
      "\u001b[35mDone building model...\u001b[0m\n",
      "\u001b[35mRestoring model...\u001b[0m\n",
      "\u001b[35mDone building model...\u001b[0m\n",
      "\u001b[35mRestoring model...\u001b[0m\n",
      "\u001b[35mDone building model...\u001b[0m\n",
      "\u001b[35mRestoring model...\u001b[0m\n",
      "\u001b[35mDone building model...\u001b[0m\n",
      "\u001b[35mRestoring model...\u001b[0m\n",
      "\u001b[35mDone building model...\u001b[0m\n",
      "\u001b[35mRestoring model...\u001b[0m\n",
      "\u001b[35mDone building model...\u001b[0m\n",
      "\u001b[35mRestoring model...\u001b[0m\n",
      "\u001b[35mDone building model...\u001b[0m\n",
      "\u001b[35mRestoring model...\u001b[0m\n",
      "\u001b[35mDone restoring model...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:27 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:27 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:27 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:27 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35mDone restoring model...\u001b[0m\n",
      "\u001b[35mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:27 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 36 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 47 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34mDone restoring model...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 44 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mDone restoring model...\u001b[0m\n",
      "\u001b[35mDone restoring model...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:27 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mDone restoring model...\u001b[0m\n",
      "\u001b[35mDone restoring model...\u001b[0m\n",
      "\u001b[35mDone restoring model...\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 36 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mDone restoring model...\u001b[0m\n",
      "\u001b[35mDone restoring model...\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35mDone restoring model...\u001b[0m\n",
      "\u001b[35mDone restoring model...\u001b[0m\n",
      "\u001b[35mDone restoring model...\u001b[0m\n",
      "\u001b[35mDone restoring model...\u001b[0m\n",
      "\u001b[35mDone restoring model...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 47 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35mDone restoring model...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 44 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 46 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 46 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 46 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 46 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2020-12-09T21:46:27.411:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=1, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 37 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 37 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 44 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 38 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 38 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 39 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 37 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:28 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 37 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 44 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 38 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 38 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 39 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 39 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 38 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:30 +0000] \"POST /invocations HTTP/1.1\" 200 37 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:30 +0000] \"POST /invocations HTTP/1.1\" 200 47 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:30 +0000] \"POST /invocations HTTP/1.1\" 200 48 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 1 records\u001b[0m\n",
      "\u001b[34mMaking predictions...\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Dec/2020:21:46:30 +0000] \"POST /invocations HTTP/1.1\" 200 36 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 39 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 38 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:29 +0000] \"POST /invocations HTTP/1.1\" 200 43 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:30 +0000] \"POST /invocations HTTP/1.1\" 200 37 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:30 +0000] \"POST /invocations HTTP/1.1\" 200 47 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:30 +0000] \"POST /invocations HTTP/1.1\" 200 48 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 1 records\u001b[0m\n",
      "\u001b[35mMaking predictions...\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Dec/2020:21:46:30 +0000] \"POST /invocations HTTP/1.1\" 200 36 \"-\" \"Go-http-client/1.1\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "timestamp_prefix = \"7\"\n",
    "job_name = 'serial-inference-batch-' + timestamp_prefix\n",
    "transformer = sagemaker.transformer.Transformer(\n",
    "    # This was the model created using PipelineModel and it contains feature processing and XGBoost\n",
    "    model_name = model_name,\n",
    "    instance_count = 1,\n",
    "    instance_type = 'ml.m5.4xlarge',\n",
    "    max_payload = 1,\n",
    "    strategy = 'SingleRecord',\n",
    "    assemble_with = 'Line',\n",
    "    output_path = output_data_path,\n",
    "    base_transform_job_name='serial-inference-batch',\n",
    "    sagemaker_session=sess,\n",
    "    accept = \"text/csv\"\n",
    ")\n",
    "transformer.transform(data = input_data_path,\n",
    "                      job_name = job_name,\n",
    "                      content_type = \"text/csv\", \n",
    "                      split_type = 'Line')\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = \"this test\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.strip()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
