{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip to section **Build Endpoint** if you already built Docker image and pushed it to ECR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Build an image that can do training and inference in SageMaker\r\n",
      "# This is a Python 2 image that uses the nginx, gunicorn, flask stack\r\n",
      "# for serving inferences in a stable way.\r\n",
      "\r\n",
      "FROM ubuntu:20.04\r\n",
      "\r\n",
      "MAINTAINER Amazon AI <sage-learner@amazon.com>\r\n",
      "\r\n",
      "ARG PYTHON_VERSION_TAG=3.8.3\r\n",
      "ARG LINK_PYTHON_TO_PYTHON3=1\r\n",
      "\r\n",
      "RUN apt-get -y update && apt-get install -y --no-install-recommends \\\r\n",
      "         wget \\\r\n",
      "         nginx \\\r\n",
      "         ca-certificates \\\r\n",
      "    && rm -rf /var/lib/apt/lists/*\r\n",
      "    \r\n",
      "RUN apt-get -qq -y update && \\\r\n",
      "    DEBIAN_FRONTEND=noninteractive apt-get -qq -y install \\\r\n",
      "        gcc \\\r\n",
      "        g++ \\\r\n",
      "        zlibc \\\r\n",
      "        zlib1g-dev \\\r\n",
      "        libssl-dev \\\r\n",
      "        libbz2-dev \\\r\n",
      "        libsqlite3-dev \\\r\n",
      "        libncurses5-dev \\\r\n",
      "        libgdbm-dev \\\r\n",
      "        libgdbm-compat-dev \\\r\n",
      "        liblzma-dev \\\r\n",
      "        libreadline-dev \\\r\n",
      "        uuid-dev \\\r\n",
      "        libffi-dev \\\r\n",
      "        tk-dev \\\r\n",
      "        curl \\\r\n",
      "        git \\\r\n",
      "        make \\\r\n",
      "        sudo \\\r\n",
      "        bash-completion \\\r\n",
      "        tree \\\r\n",
      "        vim \\\r\n",
      "        software-properties-common && \\\r\n",
      "    mv /usr/bin/lsb_release /usr/bin/lsb_release.bak && \\\r\n",
      "    apt-get -y autoclean && \\\r\n",
      "    apt-get -y autoremove && \\\r\n",
      "    rm -rf /var/lib/apt/lists/*\r\n",
      "\r\n",
      "#RUN wget https://bootstrap.pypa.io/get-pip.py && python get-pip.py\r\n",
      "#RUN apt-get -y update && apt-get install -y --no-install-recommends python3.5 \r\n",
      "\r\n",
      "# Here we get all python packages.\r\n",
      "# There's substantial overlap between scipy and numpy that we eliminate by\r\n",
      "# linking them together. Likewise, pip leaves the install caches populated which uses\r\n",
      "# a significant amount of space. These optimizations save a fair amount of space in the\r\n",
      "# image, which reduces start up time.\r\n",
      "#tensorflow==2.3.0\r\n",
      "#RUN wget https://bootstrap.pypa.io/3.3/get-pip.py && python3.5 get-pip.py\r\n",
      "COPY install_python.sh install_python.sh\r\n",
      "RUN bash install_python.sh ${PYTHON_VERSION_TAG} ${LINK_PYTHON_TO_PYTHON3} && \\\r\n",
      "    rm -r install_python.sh Python-${PYTHON_VERSION_TAG}\r\n",
      "\r\n",
      "#RUN apt-get install -y python3-pip\r\n",
      "#tensorflow-cpu\r\n",
      "RUN pip3 install --upgrade pip\r\n",
      "RUN pip3 install numpy==1.16.0 scipy scikit-learn tensorflow pandas==1.0.1 flask gevent gunicorn boto3\r\n",
      "\r\n",
      "#RUN apt-get install python-is-python3\r\n",
      "#RUN ln -s /usr/bin/python3 /usr/bin/python && \\\r\n",
      "#    ln -s /usr/bin/pip3 /usr/bin/pip\r\n",
      "    \r\n",
      "# Set some environment variables. PYTHONUNBUFFERED keeps Python from buffering our standard\r\n",
      "# output stream, which means that logs can be delivered to the user quickly. PYTHONDONTWRITEBYTECODE\r\n",
      "# keeps Python from writing the .pyc files which are unnecessary in this case. We also update\r\n",
      "# PATH so that the train and serve programs are found when the container is invoked.\r\n",
      "# Use C.UTF-8 locale to avoid issues with ASCII encoding\r\n",
      "\r\n",
      "ENV LC_ALL=C.UTF-8\r\n",
      "ENV LANG=C.UTF-8\r\n",
      "\r\n",
      "ENV PYTHONUNBUFFERED=TRUE\r\n",
      "ENV PYTHONDONTWRITEBYTECODE=TRUE\r\n",
      "ENV PATH=\"/opt/program:${PATH}\"\r\n",
      "\r\n",
      "# Set up the program in the image\r\n",
      "COPY ProtCNN /opt/program\r\n",
      "WORKDIR /opt/program"
     ]
    }
   ],
   "source": [
    "!cat container/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Befor building the image, you need to make the container able to run the file ./container/ProtCNN/serve. To do so, run the follwiong command in the terminal: <br>\n",
    "<br>\n",
    "chmod +x container/ProtCNN/serve <br>\n",
    "<br>\n",
    "Then, you can proceed with building the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/protein-annotation/inference-container/container\n",
      "Sending build context to Docker daemon  377.9kB\n",
      "Step 1/17 : FROM ubuntu:20.04\n",
      " ---> f643c72bc252\n",
      "Step 2/17 : MAINTAINER Amazon AI <sage-learner@amazon.com>\n",
      " ---> Using cache\n",
      " ---> 326b3d86eee1\n",
      "Step 3/17 : ARG PYTHON_VERSION_TAG=3.8.3\n",
      " ---> Using cache\n",
      " ---> 439310e2c915\n",
      "Step 4/17 : ARG LINK_PYTHON_TO_PYTHON3=1\n",
      " ---> Using cache\n",
      " ---> dbb5d06e3d11\n",
      "Step 5/17 : RUN apt-get -y update && apt-get install -y --no-install-recommends          wget          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 5f43ad46e6dd\n",
      "Step 6/17 : RUN apt-get -qq -y update &&     DEBIAN_FRONTEND=noninteractive apt-get -qq -y install         gcc         g++         zlibc         zlib1g-dev         libssl-dev         libbz2-dev         libsqlite3-dev         libncurses5-dev         libgdbm-dev         libgdbm-compat-dev         liblzma-dev         libreadline-dev         uuid-dev         libffi-dev         tk-dev         curl         git         make         sudo         bash-completion         tree         vim         software-properties-common &&     mv /usr/bin/lsb_release /usr/bin/lsb_release.bak &&     apt-get -y autoclean &&     apt-get -y autoremove &&     rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 7e3f10a511aa\n",
      "Step 7/17 : COPY install_python.sh install_python.sh\n",
      " ---> Using cache\n",
      " ---> df527da06b05\n",
      "Step 8/17 : RUN bash install_python.sh ${PYTHON_VERSION_TAG} ${LINK_PYTHON_TO_PYTHON3} &&     rm -r install_python.sh Python-${PYTHON_VERSION_TAG}\n",
      " ---> Using cache\n",
      " ---> c9ba70d0c5a7\n",
      "Step 9/17 : RUN pip3 install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 4fb41eb647ae\n",
      "Step 10/17 : RUN pip3 install numpy==1.16.0 scipy scikit-learn tensorflow pandas==1.0.1 flask gevent gunicorn boto3\n",
      " ---> Using cache\n",
      " ---> b7f0786a371f\n",
      "Step 11/17 : ENV LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> d81982c03df4\n",
      "Step 12/17 : ENV LANG=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> f1103152693f\n",
      "Step 13/17 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> c28d6097a86c\n",
      "Step 14/17 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> 465aabdd9c01\n",
      "Step 15/17 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 22113d090241\n",
      "Step 16/17 : COPY ProtCNN /opt/program\n",
      " ---> Using cache\n",
      " ---> 16dfa3c481c4\n",
      "Step 17/17 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> c991120bd95e\n",
      "Successfully built c991120bd95e\n",
      "Successfully tagged port-cnn-15:latest\n",
      "/home/ec2-user/SageMaker/protein-annotation/inference-container\n"
     ]
    }
   ],
   "source": [
    "%cd container\n",
    "!docker build -t port-cnn .\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push image to ECR\n",
    "import boto3\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "ecr_repository = 'port-cnn'\n",
    "tag = ':latest'\n",
    "uri_suffix = 'amazonaws.com'\n",
    "port_cnn_uri = '{}.dkr.ecr.{}.{}/{}'.format(account_id, region, uri_suffix, ecr_repository + tag)\n",
    "\n",
    "# Create ECR repository and push docker image\n",
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)\n",
    "!aws ecr create-repository --repository-name $ecr_repository\n",
    "!docker tag {ecr_repository + tag} $port_cnn_uri\n",
    "!docker push $port_cnn_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/port-cnn:latest'.format(account, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage = boto3.Session().client(service_name='sagemaker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"PortCNN-prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the location of model artifacts to ModelDataUrl field\n",
    "primary_container = {\n",
    "    'Image': image,\n",
    "    'ModelDataUrl': \"\",\n",
    "}\n",
    "\n",
    "create_model_response = sage.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Endpoint Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name_prefix = 'PortCNN-inference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_config_name = job_name_prefix + '-epc-' + timestamp\n",
    "endpoint_config_response = sage.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.m5.4xlarge',\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print('Endpoint configuration name: {}'.format(endpoint_config_name))\n",
    "print('Endpoint configuration arn:  {}'.format(endpoint_config_response['EndpointConfigArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker = boto3.client(service_name='sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_name = job_name_prefix + '-ep-' + timestamp\n",
    "print('Endpoint name: {}'.format(endpoint_name))\n",
    "\n",
    "endpoint_params = {\n",
    "    'EndpointName': endpoint_name,\n",
    "    'EndpointConfigName': endpoint_config_name,\n",
    "}\n",
    "endpoint_response = sagemaker.create_endpoint(**endpoint_params)\n",
    "print('EndpointArn = {}'.format(endpoint_response['EndpointArn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EndpointStatus = Creating\n",
      "Endpoint creation ended with EndpointStatus = InService\n"
     ]
    }
   ],
   "source": [
    "# get the status of the endpoint\n",
    "response = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = response['EndpointStatus']\n",
    "print('EndpointStatus = {}'.format(status))\n",
    "\n",
    "\n",
    "# wait until the status has changed\n",
    "sagemaker.get_waiter('endpoint_in_service').wait(EndpointName=endpoint_name)\n",
    "\n",
    "\n",
    "# print the status of the endpoint\n",
    "endpoint_response = sagemaker.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = endpoint_response['EndpointStatus']\n",
    "print('Endpoint creation ended with EndpointStatus = {}'.format(status))\n",
    "\n",
    "if status != 'InService':\n",
    "    raise Exception('Endpoint creation failed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sample test\n",
    "sample_test = []\n",
    "\n",
    "with open('sample-test.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        sample_test.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RHARLVSRFSDLYTVERLDAQTLLRRYIPDIEMVQRIIFIAVMESFQKAKLAYRKFKQQVRKTLSTSHFGPESLEDAAVDYIVRNLDLYDVLCSVNVRENDFVFSRKVFFQPVTTFCMYVLPPYLSALIKKNPATSSCSPPLLYIAPTSRGHSNIMYRRSFDSDFSAPLVVYYVWPALVEGSTVLVKGEA',\n",
       " 'LDVEIADTDPKREQGLMFRRSLSENQGMIFLFGREREITMWMKNTFIPLDMVFIGDDWRVVSIAQNAEPFSTDVISSRRPASRVLEIGAGQAKKLGLKVGDRVSL',\n",
       " 'EKLEVWKLSKNFATKIYKNTENFPNEEKFGLVSQLRRAAVSVASNLAEGSSRKSKKDQAHFSQIAYSSLMEVLCQLEIAKDIGYISENDLQDLRSDASKIAYMINS',\n",
       " 'SLSEARRFNTSYVGTEHILLGLLREGEGVAVRILMEQGIDFNRVREEIVKMLS',\n",
       " 'AINELKKELKAVILAHYYQDPDIQDIADYIGDSLGLSQQAATTDKEVIVFAGVHFMAETAKILNPDKLVLLPDLEAGCSLADSCPPEEFAQFKTQYPDAIVVSYINCTADIKAMSDVICTSSNAVKIVNQLPKDRPIIFGPDRNLGRYVAQQTGRDLILWQGSCIVHETFSERRIVQLKIEHPSAEIIAHPECEEPVLRHANYIGSTTALLKYSQQSPQDSFIVATEPGIIHQMQKEAPNKTFIPAPAMNNCACNECPYMRLNTLEKLYLAMKHKQPEIIMDESTRKAALKPIQRMLE']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = boto3.Session().client(service_name='runtime.sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'a036c535-ec7d-45be-a378-50f7cdf239c1', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'a036c535-ec7d-45be-a378-50f7cdf239c1', 'x-amzn-invoked-production-variant': 'AllTraffic', 'date': 'Tue, 5 Jan 2021 20:23:20 GMT', 'content-type': 'text/csv; charset=utf-8', 'content-length': '37'}, 'RetryAttempts': 0}, 'ContentType': 'text/csv; charset=utf-8', 'InvokedProductionVariant': 'AllTraffic', 'Body': <botocore.response.StreamingBody object at 0x7fbbd34b26a0>}\n"
     ]
    }
   ],
   "source": [
    "# Invoke model with a single sample\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                           ContentType= 'text/csv', \n",
    "                                           Body=sample_test[0] + \"\\r\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"('PF16026.5', 'MIEAP', 0.99273646)\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# response needs some processing to remove the five characters ' AND \" AND ( AND ) AND \\n\n",
    "r = response['Body'].read().decode()\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PF16026.5', 'MIEAP', '0.99273646']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Match ' OR \" OR ( OR ) OR \\n\n",
    "# The result is a list containing Family Accession, Family ID, and confidence score\n",
    "re.sub(\"\\'|\\\"|\\(|\\)|\\n\", '', r).split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "for payload in sample_test:\n",
    "    if (payload != ''):\n",
    "        response = runtime.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                           ContentType= 'text/csv', \n",
    "                                           Body=payload + \"\\r\\n\")\n",
    "        response = json.loads(response['Body'].read().decode())\n",
    "        response = re.sub(\"\\'|\\\"|\\(|\\)|\\n\", '', response).split(\", \")\n",
    "        response.append(payload)\n",
    "        \n",
    "        responses.append(tuple(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PF16026.5',\n",
       "  'MIEAP',\n",
       "  '0.99273646',\n",
       "  'RHARLVSRFSDLYTVERLDAQTLLRRYIPDIEMVQRIIFIAVMESFQKAKLAYRKFKQQVRKTLSTSHFGPESLEDAAVDYIVRNLDLYDVLCSVNVRENDFVFSRKVFFQPVTTFCMYVLPPYLSALIKKNPATSSCSPPLLYIAPTSRGHSNIMYRRSFDSDFSAPLVVYYVWPALVEGSTVLVKGEA'),\n",
       " ('PF02643.15',\n",
       "  'DUF192',\n",
       "  '0.9993938',\n",
       "  'LDVEIADTDPKREQGLMFRRSLSENQGMIFLFGREREITMWMKNTFIPLDMVFIGDDWRVVSIAQNAEPFSTDVISSRRPASRVLEIGAGQAKKLGLKVGDRVSL'),\n",
       " ('PF05635.11',\n",
       "  '23S_rRNA_IVP',\n",
       "  '0.99970835',\n",
       "  'EKLEVWKLSKNFATKIYKNTENFPNEEKFGLVSQLRRAAVSVASNLAEGSSRKSKKDQAHFSQIAYSSLMEVLCQLEIAKDIGYISENDLQDLRSDASKIAYMINS'),\n",
       " ('PF02861.20',\n",
       "  'Clp_N',\n",
       "  '0.8881429',\n",
       "  'SLSEARRFNTSYVGTEHILLGLLREGEGVAVRILMEQGIDFNRVREEIVKMLS'),\n",
       " ('PF02445.16',\n",
       "  'NadA',\n",
       "  '0.99999774',\n",
       "  'AINELKKELKAVILAHYYQDPDIQDIADYIGDSLGLSQQAATTDKEVIVFAGVHFMAETAKILNPDKLVLLPDLEAGCSLADSCPPEEFAQFKTQYPDAIVVSYINCTADIKAMSDVICTSSNAVKIVNQLPKDRPIIFGPDRNLGRYVAQQTGRDLILWQGSCIVHETFSERRIVQLKIEHPSAEIIAHPECEEPVLRHANYIGSTTALLKYSQQSPQDSFIVATEPGIIHQMQKEAPNKTFIPAPAMNNCACNECPYMRLNTLEKLYLAMKHKQPEIIMDESTRKAALKPIQRMLE')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
